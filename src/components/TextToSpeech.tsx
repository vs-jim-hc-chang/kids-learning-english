import { useState, useCallback, useImperativeHandle, forwardRef, useRef, useEffect } from 'react';

interface TextToSpeechProps {
  text: string;
  onSpeakStart?: () => void;
  onSpeakEnd?: () => void;
}

// æš´éœ²çµ¦å¤–éƒ¨å‘¼å«çš„æ–¹æ³•
export interface TextToSpeechRef {
  speakText: (text: string, lang: 'en' | 'zh') => Promise<void>;
  stop: () => void;
}

// èªéŸ³åå¥½è¨­å®šï¼ˆæŒ‰å„ªå…ˆé †åºæ’åˆ—ï¼‰
const VOICE_PREFERENCES = {
  en: [
    // Windows 11 Neural voices
    'Microsoft Aria Online (Natural)',
    'Microsoft Jenny Online (Natural)',
    'Microsoft Guy Online (Natural)',
    // macOS voices
    'Samantha',
    'Karen',
    'Daniel',
    // Chrome/Android
    'Google US English',
    // å‚™ç”¨
    'en-US',
    'en'
  ],
  zh: [
    // Windows 11 Neural voices (Taiwan)
    'Microsoft HsiaoChen Online (Natural)',
    'Microsoft YunJhe Online (Natural)',
    // Windows 11 Neural voices (China)
    'Microsoft Xiaoxiao Online (Natural)',
    'Microsoft Yunyang Online (Natural)',
    // macOS voices
    'Mei-Jia',
    'Ting-Ting',
    // Chrome/Android
    'Google åœ‹èªï¼ˆè‡ºç£ï¼‰',
    'Google æ™®é€šè¯ï¼ˆä¸­å›½å¤§é™†ï¼‰',
    // å‚™ç”¨
    'zh-TW',
    'zh-CN',
    'zh'
  ]
};

// æ‰¾åˆ°æœ€ä½³èªéŸ³
function findBestVoice(voices: SpeechSynthesisVoice[], lang: 'en' | 'zh'): SpeechSynthesisVoice | null {
  const preferences = VOICE_PREFERENCES[lang];

  // æŒ‰åå¥½é †åºå°‹æ‰¾
  for (const pref of preferences) {
    const found = voices.find(v =>
      v.name.includes(pref) ||
      v.lang.startsWith(pref)
    );
    if (found) return found;
  }

  // å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œæ‰¾ä»»ä½•ç¬¦åˆèªè¨€çš„
  const langPrefix = lang === 'en' ? 'en' : 'zh';
  return voices.find(v => v.lang.startsWith(langPrefix)) || null;
}

export const TextToSpeech = forwardRef<TextToSpeechRef, TextToSpeechProps>(
  function TextToSpeech({ text, onSpeakStart, onSpeakEnd }, ref) {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);
    const [selectedVoices, setSelectedVoices] = useState<{en: string; zh: string}>({en: '', zh: ''});
    const utteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
    const isStoppedRef = useRef(false);

    // è¼‰å…¥èªéŸ³åˆ—è¡¨
    useEffect(() => {
      const loadVoices = () => {
        const availableVoices = speechSynthesis.getVoices();
        if (availableVoices.length > 0) {
          setVoices(availableVoices);

          // æ‰¾åˆ°æœ€ä½³èªéŸ³ä¸¦è¨˜éŒ„
          const bestEn = findBestVoice(availableVoices, 'en');
          const bestZh = findBestVoice(availableVoices, 'zh');

          setSelectedVoices({
            en: bestEn?.name || 'ç³»çµ±é è¨­',
            zh: bestZh?.name || 'ç³»çµ±é è¨­'
          });

          console.log('Available voices:', availableVoices.map(v => `${v.name} (${v.lang})`));
          console.log('Selected EN voice:', bestEn?.name);
          console.log('Selected ZH voice:', bestZh?.name);
        }
      };

      loadVoices();
      speechSynthesis.onvoiceschanged = loadVoices;

      return () => {
        speechSynthesis.onvoiceschanged = null;
      };
    }, []);

    // åœæ­¢æ’­æ”¾
    const stop = useCallback(() => {
      isStoppedRef.current = true;
      speechSynthesis.cancel();
      utteranceRef.current = null;
      setIsSpeaking(false);
      setIsLoading(false);
    }, []);

    // å…ƒä»¶å¸è¼‰æ™‚æ¸…ç†
    useEffect(() => {
      return () => {
        speechSynthesis.cancel();
      };
    }, []);

    // ä½¿ç”¨ Web Speech API æœ—è®€
    const speakWithWebSpeech = useCallback((
      textToSpeak: string,
      lang: 'en' | 'zh',
      rate: number = 1
    ): Promise<void> => {
      return new Promise((resolve) => {
        // é‡è¨­åœæ­¢æ¨™è¨˜
        isStoppedRef.current = false;

        // å…ˆå–æ¶ˆä»»ä½•é€²è¡Œä¸­çš„èªéŸ³
        speechSynthesis.cancel();

        const utterance = new SpeechSynthesisUtterance(textToSpeak);
        utteranceRef.current = utterance;

        // è¨­å®šèªè¨€
        utterance.lang = lang === 'en' ? 'en-US' : 'zh-TW';
        utterance.rate = rate;
        utterance.pitch = 1;
        utterance.volume = 1;

        // é¸æ“‡æœ€ä½³èªéŸ³
        const bestVoice = findBestVoice(voices, lang);
        if (bestVoice) {
          utterance.voice = bestVoice;
        }

        utterance.onend = () => {
          utteranceRef.current = null;
          resolve();
        };

        utterance.onerror = (event) => {
          utteranceRef.current = null;
          // å¿½ç•¥ interrupted éŒ¯èª¤ï¼ˆæ‰‹å‹•åœæ­¢æ™‚æœƒè§¸ç™¼ï¼‰
          if (event.error !== 'interrupted') {
            console.error('Speech error:', event.error);
          }
          resolve();
        };

        // æª¢æŸ¥æ˜¯å¦è¢«åœæ­¢
        if (isStoppedRef.current) {
          resolve();
          return;
        }

        speechSynthesis.speak(utterance);
      });
    }, [voices]);

    // æš´éœ²æ–¹æ³•çµ¦å¤–éƒ¨å‘¼å«ï¼ˆä¾› CarMode ä½¿ç”¨ï¼‰
    useImperativeHandle(ref, () => ({
      speakText: async (textToSpeak: string, lang: 'en' | 'zh') => {
        const rate = lang === 'en' ? 0.85 : 0.95; // è‹±æ–‡ç¨æ…¢ï¼Œä¸­æ–‡æ­£å¸¸åæ…¢
        await speakWithWebSpeech(textToSpeak, lang, rate);
      },
      stop
    }), [speakWithWebSpeech, stop]);

    // å®Œæ•´æœ—è®€æµç¨‹ï¼šæç¤ºèª + ä¾‹å¥
    const handleSpeak = useCallback(async () => {
      if (isSpeaking || isLoading) {
        stop();
        return;
      }

      setIsLoading(true);
      setIsSpeaking(true);
      onSpeakStart?.();

      try {
        // 1. èªª "Please repeat after me"ï¼ˆè‹±æ–‡æç¤ºï¼‰
        await speakWithWebSpeech("Please repeat after me", 'en', 1);

        if (isStoppedRef.current) return;

        // 2. çŸ­æš«åœé “
        await new Promise(resolve => setTimeout(resolve, 500));

        if (isStoppedRef.current) return;

        // 3. æœ—è®€ä¾‹å¥ï¼ˆè¼ƒæ…¢é€Ÿåº¦ï¼Œè‹±æ–‡ï¼‰
        await speakWithWebSpeech(text, 'en', 0.8);

        if (isStoppedRef.current) return;

        // 4. åœé “å¾Œå†æœ—è®€ä¸€æ¬¡
        await new Promise(resolve => setTimeout(resolve, 1000));

        if (isStoppedRef.current) return;

        await speakWithWebSpeech(text, 'en', 0.8);
      } catch (error) {
        console.error('TTS error:', error);
      }

      setIsSpeaking(false);
      setIsLoading(false);
      onSpeakEnd?.();
    }, [text, isSpeaking, isLoading, speakWithWebSpeech, stop, onSpeakStart, onSpeakEnd]);

    // åªæœ—è®€ä¾‹å¥ä¸€æ¬¡
    const handleSpeakOnce = useCallback(async () => {
      if (isSpeaking || isLoading) {
        stop();
        return;
      }

      setIsLoading(true);
      setIsSpeaking(true);
      onSpeakStart?.();

      try {
        await speakWithWebSpeech(text, 'en', 0.85);
      } catch (error) {
        console.error('TTS error:', error);
      }

      setIsSpeaking(false);
      setIsLoading(false);
      onSpeakEnd?.();
    }, [text, isSpeaking, isLoading, speakWithWebSpeech, stop, onSpeakStart, onSpeakEnd]);

    return (
      <div className="text-to-speech">
        {/* èªéŸ³è³‡è¨Š */}
        <div className="voice-info">
          <span>ğŸ—£ï¸ è‹±æ–‡ï¼š{selectedVoices.en || 'è¼‰å…¥ä¸­...'}</span>
          <span>ğŸ—£ï¸ ä¸­æ–‡ï¼š{selectedVoices.zh || 'è¼‰å…¥ä¸­...'}</span>
        </div>

        <div className="tts-buttons">
          <button
            onClick={handleSpeak}
            className={`tts-btn main-speak ${isSpeaking ? 'speaking' : ''}`}
            disabled={isLoading && !isSpeaking}
          >
            {isLoading && !isSpeaking ? 'â³ è¼‰å…¥ä¸­...' : isSpeaking ? 'ğŸ”Š æœ—è®€ä¸­...' : 'ğŸ—£ï¸ è·Ÿè‘—èªª'}
          </button>

          <button
            onClick={handleSpeakOnce}
            className="tts-btn quick-speak"
            disabled={isSpeaking || isLoading}
          >
            ğŸ”ˆ å†è½ä¸€æ¬¡
          </button>
        </div>
      </div>
    );
  }
);
