import { useState, useCallback, useImperativeHandle, forwardRef, useRef, useEffect } from 'react';
import { Communicate } from 'edge-tts-universal';

interface TextToSpeechProps {
  text: string;
  onSpeakStart?: () => void;
  onSpeakEnd?: () => void;
}

// æš´éœ²çµ¦å¤–éƒ¨å‘¼å«çš„æ–¹æ³•
export interface TextToSpeechRef {
  speakText: (text: string, lang: 'en' | 'zh') => Promise<void>;
  stop: () => void;
}

// Edge TTS èªéŸ³è¨­å®š
const VOICE_CONFIG = {
  // å°ç£å¥³è² - æ›‰è‡»ï¼ˆè‡ªç„¶è¦ªåˆ‡ï¼‰
  zh: 'zh-TW-HsiaoChenNeural',
  // ç¾å¼è‹±æ–‡å¥³è² - Jennyï¼ˆè‡ªç„¶æµæš¢ï¼‰
  en: 'en-US-JennyNeural'
};

export const TextToSpeech = forwardRef<TextToSpeechRef, TextToSpeechProps>(
  function TextToSpeech({ text, onSpeakStart, onSpeakEnd }, ref) {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const audioRef = useRef<HTMLAudioElement | null>(null);
    const audioUrlRef = useRef<string | null>(null);
    const isStoppedRef = useRef(false);

    // æ¸…ç† Object URL
    const cleanupAudioUrl = useCallback(() => {
      if (audioUrlRef.current) {
        URL.revokeObjectURL(audioUrlRef.current);
        audioUrlRef.current = null;
      }
    }, []);

    // åœæ­¢æ’­æ”¾
    const stop = useCallback(() => {
      isStoppedRef.current = true;
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
        audioRef.current = null;
      }
      cleanupAudioUrl();
      setIsSpeaking(false);
      setIsLoading(false);
    }, [cleanupAudioUrl]);

    // å…ƒä»¶å¸è¼‰æ™‚æ¸…ç†
    useEffect(() => {
      return () => {
        if (audioRef.current) {
          audioRef.current.pause();
          audioRef.current = null;
        }
        cleanupAudioUrl();
      };
    }, [cleanupAudioUrl]);

    // ä½¿ç”¨ Edge TTS æœ—è®€
    const speakWithEdgeTTS = useCallback(async (
      textToSpeak: string,
      lang: 'en' | 'zh',
      rate: number = 0
    ): Promise<void> => {
      // é‡è¨­åœæ­¢æ¨™è¨˜
      isStoppedRef.current = false;

      try {
        const voice = VOICE_CONFIG[lang];

        // è¨­å®šèªé€Ÿ rate: -50 åˆ° +100ï¼Œ0 æ˜¯æ­£å¸¸é€Ÿåº¦
        const rateStr = rate >= 0 ? `+${rate}%` : `${rate}%`;

        // å»ºç«‹ Communicate å¯¦ä¾‹
        const communicate = new Communicate(textToSpeak, {
          voice,
          rate: rateStr,
          pitch: '+0Hz',
          volume: '+0%'
        });

        // æ”¶é›†éŸ³è¨Šè³‡æ–™
        const audioChunks: Uint8Array[] = [];

        // ä¸²æµå–å¾—éŸ³è¨Šï¼ˆæª¢æŸ¥æ˜¯å¦è¢«åœæ­¢ï¼‰
        for await (const chunk of communicate.stream()) {
          if (isStoppedRef.current) {
            return; // æå‰çµæŸ
          }
          if (chunk.type === 'audio' && chunk.data) {
            audioChunks.push(new Uint8Array(chunk.data));
          }
        }

        // å†æ¬¡æª¢æŸ¥æ˜¯å¦è¢«åœæ­¢
        if (isStoppedRef.current) {
          return;
        }

        // åˆä½µéŸ³è¨Šè³‡æ–™
        const totalLength = audioChunks.reduce((acc, chunk) => acc + chunk.length, 0);
        const audioData = new Uint8Array(totalLength);
        let offset = 0;
        for (const chunk of audioChunks) {
          audioData.set(chunk, offset);
          offset += chunk.length;
        }

        // å»ºç«‹ Blob å’Œæ’­æ”¾
        const audioBlob = new Blob([audioData], { type: 'audio/mpeg' });

        // æ¸…ç†èˆŠçš„ URL
        cleanupAudioUrl();

        const audioUrl = URL.createObjectURL(audioBlob);
        audioUrlRef.current = audioUrl;

        const audio = new Audio(audioUrl);
        audioRef.current = audio;

        // ä½¿ç”¨ Promise ç­‰å¾…æ’­æ”¾å®Œæˆ
        await new Promise<void>((resolve) => {
          audio.onended = () => {
            cleanupAudioUrl();
            audioRef.current = null;
            resolve();
          };

          audio.onerror = () => {
            cleanupAudioUrl();
            audioRef.current = null;
            console.error('Audio playback error');
            resolve();
          };

          audio.play().catch(() => {
            cleanupAudioUrl();
            audioRef.current = null;
            resolve();
          });
        });
      } catch (error) {
        console.error('Edge TTS error:', error);
        // ç™¼ç”ŸéŒ¯èª¤æ™‚ä¸æ‹‹å‡ºï¼Œé¿å…æµç¨‹ä¸­æ–·
      }
    }, [cleanupAudioUrl]);

    // æš´éœ²æ–¹æ³•çµ¦å¤–éƒ¨å‘¼å«ï¼ˆä¾› CarMode ä½¿ç”¨ï¼‰
    useImperativeHandle(ref, () => ({
      speakText: async (textToSpeak: string, lang: 'en' | 'zh') => {
        const rate = lang === 'en' ? -15 : -5; // è‹±æ–‡ç¨æ…¢ï¼Œä¸­æ–‡æ­£å¸¸åæ…¢
        await speakWithEdgeTTS(textToSpeak, lang, rate);
      },
      stop
    }), [speakWithEdgeTTS, stop]);

    // å®Œæ•´æœ—è®€æµç¨‹ï¼šæç¤ºèª + ä¾‹å¥
    const handleSpeak = useCallback(async () => {
      if (isSpeaking || isLoading) {
        stop();
        return;
      }

      setIsLoading(true);
      setIsSpeaking(true);
      onSpeakStart?.();

      try {
        // 1. èªª "Please repeat after me"ï¼ˆè‹±æ–‡æç¤ºï¼‰
        await speakWithEdgeTTS("Please repeat after me", 'en', 0);

        // 2. çŸ­æš«åœé “
        await new Promise(resolve => setTimeout(resolve, 500));

        // 3. æœ—è®€ä¾‹å¥ï¼ˆè¼ƒæ…¢é€Ÿåº¦ï¼Œè‹±æ–‡ï¼‰
        await speakWithEdgeTTS(text, 'en', -20);

        // 4. åœé “å¾Œå†æœ—è®€ä¸€æ¬¡
        await new Promise(resolve => setTimeout(resolve, 1000));
        await speakWithEdgeTTS(text, 'en', -20);
      } catch (error) {
        console.error('TTS error:', error);
      }

      setIsSpeaking(false);
      setIsLoading(false);
      onSpeakEnd?.();
    }, [text, isSpeaking, isLoading, speakWithEdgeTTS, stop, onSpeakStart, onSpeakEnd]);

    // åªæœ—è®€ä¾‹å¥ä¸€æ¬¡
    const handleSpeakOnce = useCallback(async () => {
      if (isSpeaking || isLoading) {
        stop();
        return;
      }

      setIsLoading(true);
      setIsSpeaking(true);
      onSpeakStart?.();

      try {
        await speakWithEdgeTTS(text, 'en', -15);
      } catch (error) {
        console.error('TTS error:', error);
      }

      setIsSpeaking(false);
      setIsLoading(false);
      onSpeakEnd?.();
    }, [text, isSpeaking, isLoading, speakWithEdgeTTS, stop, onSpeakStart, onSpeakEnd]);

    return (
      <div className="text-to-speech">
        {/* èªéŸ³è³‡è¨Š */}
        <div className="voice-info">
          <span>ğŸ—£ï¸ è‹±æ–‡ï¼šJenny (ç¾å¼)</span>
          <span>ğŸ—£ï¸ ä¸­æ–‡ï¼šæ›‰è‡» (å°ç£)</span>
        </div>

        <div className="tts-buttons">
          <button
            onClick={handleSpeak}
            className={`tts-btn main-speak ${isSpeaking ? 'speaking' : ''}`}
            disabled={isLoading && !isSpeaking}
          >
            {isLoading && !isSpeaking ? 'â³ è¼‰å…¥ä¸­...' : isSpeaking ? 'ğŸ”Š æœ—è®€ä¸­...' : 'ğŸ—£ï¸ è·Ÿè‘—èªª'}
          </button>

          <button
            onClick={handleSpeakOnce}
            className="tts-btn quick-speak"
            disabled={isSpeaking || isLoading}
          >
            ğŸ”ˆ å†è½ä¸€æ¬¡
          </button>
        </div>
      </div>
    );
  }
);
